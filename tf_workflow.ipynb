{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Workflow\n",
    "\n",
    "after: https://www.tensorflow.org/versions/r0.12/get_started/index.html\n",
    "\n",
    "_Just to get a feeling for the basic code layout_ ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset that is perfect for linear regression ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  -3.1018754 ,  -62.7304139 ],\n",
       "       [  -2.12574666, -129.18560592],\n",
       "       [  -7.37152683,  -75.52925676],\n",
       "       [  -0.71957311,   38.75096929],\n",
       "       [  -6.43972844, -174.94574881],\n",
       "       [   2.88979729,  -22.39928501],\n",
       "       [   4.14144182,  -33.83429152],\n",
       "       [  -4.59368099,  -90.6679126 ],\n",
       "       [  -8.19492806,  106.32021058],\n",
       "       [  -0.38991123, -141.64182244],\n",
       "       [  -2.83595347,  -42.67858726],\n",
       "       [   2.39947586,  156.17894114],\n",
       "       [   0.80495751,   27.27404219],\n",
       "       [   9.55891775,  184.43781491],\n",
       "       [   8.73485272,  136.79280099],\n",
       "       [   1.68264807, -126.23694008],\n",
       "       [   6.64079137,  108.79939101],\n",
       "       [  -7.6601185 , -188.87438308],\n",
       "       [   9.88300128,  -25.15139557],\n",
       "       [  -4.67739351,   82.21387429]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X has 20 rows and 2 columns\n",
    "X_data = np.random.uniform(-10,10,(20,2))\n",
    "X_data[:,1] = X_data[:,1] * 20 + 2\n",
    "print(X_data.shape)\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  83.4247877 ,  152.80836593,   83.41467627,  -10.90968862,\n",
       "        185.62656349,   61.06867689,   76.25861697,  106.88686963,\n",
       "       -100.90499476,  170.47208875,   64.17072684, -118.98051354,\n",
       "          5.14083034, -125.76106167,  -80.58824284,  161.2848843 ,\n",
       "        -58.87701689,  195.89402757,   84.80039942,  -66.24605481])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our y happens to be perfectly correlated...\n",
    "y_data = 30 + 3 * X_data[:,0] - X_data[:,1]\n",
    "print(y_data.shape)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, define the whole computational graph.\n",
    "\n",
    "Declare placeholders for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Placeholder:0' shape=(?, 2) dtype=float64>,\n",
       " <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float64, [None, 2])\n",
    "y = tf.placeholder(tf.float64, [None])\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a weight vector and the bias, a scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(2), Dimension(1)]), TensorShape([Dimension(1)]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the weights will be randomly initialized to small values\n",
    "W = tf.Variable(tf.truncated_normal([2,1], stddev=1,dtype='float64'))\n",
    "b = tf.Variable(tf.zeros([1.0], dtype='float64'))\n",
    "W.get_shape(), b.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now tried to evaluate W, we'd get an error, as we don't have created a Session yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#W.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the equation for predicting y from X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add:0' shape=(?, 1) dtype=float64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a linear model\n",
    "y_hat = tf.add(tf.matmul(X, W), b)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define our loss function, choosing MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=<unknown> dtype=float64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - tf.squeeze(y_hat)))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose an optimization method and a learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "optimizer = tf.train.AdamOptimizer(1e-2)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, before executing the computation, define a graph node to initialize the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can run the computation:\n",
    "\n",
    "First, create a TensorFlow Session to execute the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the initialized weights vector and the bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67435871],\n",
       "       [-0.11817936]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.eval(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.eval(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: W = [[ 0.66435871]\n",
      " [-0.12817936]], b = [ 0.01], loss = 9997.577515295707\n",
      "Step 100: W = [[ 0.17554054]\n",
      " [-0.8427924 ]], b = [ 0.95403785], loss = 1237.6127295439514\n",
      "Step 200: W = [[ 0.81560983]\n",
      " [-0.96758979]], b = [ 1.82987611], loss = 929.1319231098756\n",
      "Step 300: W = [[ 1.51103953]\n",
      " [-0.98798137]], b = [ 2.71425816], loss = 808.4008694257975\n",
      "Step 400: W = [[ 2.06895755]\n",
      " [-1.00263977]], b = [ 3.60167886], loss = 720.6076266487938\n",
      "Step 500: W = [[ 2.49186286]\n",
      " [-1.01338059]], b = [ 4.48448355], loss = 654.6266303323534\n",
      "Step 600: W = [[ 2.79351701]\n",
      " [-1.02073697]], b = [ 5.35938111], loss = 601.9377144824336\n",
      "Step 700: W = [[ 2.99449275]\n",
      " [-1.02532323]], b = [ 6.22482503], loss = 556.9092853349332\n",
      "Step 800: W = [[ 3.11837459]\n",
      " [-1.02780137]], b = [ 7.07999874], loss = 516.3285284931341\n",
      "Step 900: W = [[ 3.1878236 ]\n",
      " [-1.02879725]], b = [ 7.92438187], loss = 478.61102214885057\n",
      "Step 1000: W = [[ 3.22179437]\n",
      " [-1.02883216]], b = [ 8.757562], loss = 443.0735018002018\n",
      "Step 1100: W = [[ 3.23440164]\n",
      " [-1.02829393]], b = [ 9.57916244], loss = 409.4474255049439\n",
      "Step 1200: W = [[ 3.23513943]\n",
      " [-1.02744346]], b = [ 10.38882253], loss = 377.62328791964126\n",
      "Step 1300: W = [[ 3.22982822]\n",
      " [-1.0264408 ]], b = [ 11.18619766], loss = 347.5413553378938\n",
      "Step 1400: W = [[ 3.22173626]\n",
      " [-1.02537592]], b = [ 11.97096257], loss = 319.15332893969105\n",
      "Step 1500: W = [[ 3.21254689]\n",
      " [-1.02429528]], b = [ 12.74281223], loss = 292.4115771158962\n",
      "Step 1600: W = [[ 3.20305402]\n",
      " [-1.02322089]], b = [ 13.50145938], loss = 267.2670691580314\n",
      "Step 1700: W = [[ 3.19359834]\n",
      " [-1.02216233]], b = [ 14.24662965], loss = 243.66947222236703\n",
      "Step 1800: W = [[ 3.18431086]\n",
      " [-1.02112345]], b = [ 14.97805583], loss = 221.56757072301562\n",
      "Step 1900: W = [[ 3.17523495]\n",
      " [-1.02010565]], b = [ 15.69547211], loss = 200.90962200940044\n",
      "Step 2000: W = [[ 3.16638139]\n",
      " [-1.01910949]], b = [ 16.3986092], loss = 181.64360462203146\n",
      "Step 2100: W = [[ 3.15775063]\n",
      " [-1.01813525]], b = [ 17.08719029], loss = 163.71738319234208\n",
      "Step 2200: W = [[ 3.14934087]\n",
      " [-1.01718314]], b = [ 17.76092789], loss = 147.07881411077034\n",
      "Step 2300: W = [[ 3.14115046]\n",
      " [-1.01625342]], b = [ 18.41952155], loss = 131.67580935137522\n",
      "Step 2400: W = [[ 3.13317857]\n",
      " [-1.01534638]], b = [ 19.06265631], loss = 117.45637241557498\n",
      "Step 2500: W = [[ 3.1254252 ]\n",
      " [-1.01446236]], b = [ 19.69000179], loss = 104.36861780733189\n",
      "Step 2600: W = [[ 3.11789109]\n",
      " [-1.01360173]], b = [ 20.30121193], loss = 92.36077981125133\n",
      "Step 2700: W = [[ 3.11057763]\n",
      " [-1.01276489]], b = [ 20.89592528], loss = 81.38121867007207\n",
      "Step 2800: W = [[ 3.10348676]\n",
      " [-1.0119523 ]], b = [ 21.47376595], loss = 71.37842836610335\n",
      "Step 2900: W = [[ 3.09662088]\n",
      " [-1.01116441]], b = [ 22.03434518], loss = 62.301051154621305\n",
      "Step 3000: W = [[ 3.0899828 ]\n",
      " [-1.01040173]], b = [ 22.57726354], loss = 54.09790253787791\n",
      "Step 3100: W = [[ 3.08357565]\n",
      " [-1.00966476]], b = [ 23.10211383], loss = 46.718009690579876\n",
      "Step 3200: W = [[ 3.07740279]\n",
      " [-1.00895402]], b = [ 23.60848484], loss = 40.11066663338387\n",
      "Step 3300: W = [[ 3.07146775]\n",
      " [-1.00827005]], b = [ 24.09596585], loss = 34.225508434233085\n",
      "Step 3400: W = [[ 3.06577414]\n",
      " [-1.00761337]], b = [ 24.564152], loss = 29.0126068688705\n",
      "Step 3500: W = [[ 3.06032554]\n",
      " [-1.00698448]], b = [ 25.01265065], loss = 24.422588277014235\n",
      "Step 3600: W = [[ 3.05512544]\n",
      " [-1.00638389]], b = [ 25.4410886], loss = 20.406775101022404\n",
      "Step 3700: W = [[ 3.05017709]\n",
      " [-1.00581203]], b = [ 25.8491203], loss = 16.917350189790394\n",
      "Step 3800: W = [[ 3.04548339]\n",
      " [-1.00526933]], b = [ 26.23643692], loss = 13.907543207742837\n",
      "Step 3900: W = [[ 3.04104678]\n",
      " [-1.00475611]], b = [ 26.60277626], loss = 11.331836402683553\n",
      "Step 4000: W = [[ 3.03686907]\n",
      " [-1.00427264]], b = [ 26.94793328], loss = 9.146185866377394\n",
      "Step 4100: W = [[ 3.03295137]\n",
      " [-1.00381911]], b = [ 27.27177107], loss = 7.308253097231166\n",
      "Step 4200: W = [[ 3.02929386]\n",
      " [-1.00339556]], b = [ 27.574232], loss = 5.777639914717168\n",
      "Step 4300: W = [[ 3.02589572]\n",
      " [-1.00300194]], b = [ 27.8553486], loss = 4.5161187599329935\n",
      "Step 4400: W = [[ 3.02275499]\n",
      " [-1.00263806]], b = [ 28.1152538], loss = 3.487848979630715\n",
      "Step 4500: W = [[ 3.01986844]\n",
      " [-1.00230357]], b = [ 28.35418999], loss = 2.6595692985886545\n",
      "Step 4600: W = [[ 3.01723146]\n",
      " [-1.00199794]], b = [ 28.57251628], loss = 2.000756494361968\n",
      "Step 4700: W = [[ 3.01483805]\n",
      " [-1.00172051]], b = [ 28.77071353], loss = 1.4837410064864114\n",
      "Step 4800: W = [[ 3.01268075]\n",
      " [-1.00147042]], b = [ 28.94938656], loss = 1.083771682222141\n",
      "Step 4900: W = [[ 3.01075063]\n",
      " [-1.00124664]], b = [ 29.10926294], loss = 0.7790241819873274\n",
      "Step 5000: W = [[ 3.0090374]\n",
      " [-1.001048 ]], b = [ 29.25118825], loss = 0.5505505361563972\n",
      "Step 5100: W = [[ 3.00752945]\n",
      " [-1.00087315]], b = [ 29.37611749], loss = 0.3821708048750136\n",
      "Step 5200: W = [[ 3.00621402]\n",
      " [-1.00072062]], b = [ 29.48510266], loss = 0.26031139895545713\n",
      "Step 5300: W = [[ 3.00507742]\n",
      " [-1.00058881]], b = [ 29.57927683], loss = 0.1737979871989932\n",
      "Step 5400: W = [[ 3.00410517]\n",
      " [-1.00047607]], b = [ 29.65983521], loss = 0.11361367263842008\n",
      "Step 5500: W = [[ 3.00328236]\n",
      " [-1.00038065]], b = [ 29.72801381], loss = 0.07263493998976037\n",
      "Step 5600: W = [[ 3.00259382]\n",
      " [-1.0003008 ]], b = [ 29.78506672], loss = 0.045358556722189594\n",
      "Step 5700: W = [[ 3.00202449]\n",
      " [-1.00023478]], b = [ 29.83224286], loss = 0.027632100549541093\n",
      "Step 5800: W = [[ 3.00155962]\n",
      " [-1.00018087]], b = [ 29.87076343], loss = 0.016399203312096267\n",
      "Step 5900: W = [[ 3.00118506]\n",
      " [-1.00013743]], b = [ 29.90180083], loss = 0.009468201576606465\n",
      "Step 6000: W = [[ 3.00088747]\n",
      " [-1.00010292]], b = [ 29.92646026], loss = 0.005310018887139173\n",
      "Step 6100: W = [[ 3.00065451]\n",
      " [-1.0000759 ]], b = [ 29.94576444], loss = 0.0028881523164094487\n",
      "Step 6200: W = [[ 3.00047497]\n",
      " [-1.00005508]], b = [ 29.96064226], loss = 0.0015209406217666067\n",
      "Step 6300: W = [[ 3.00033885]\n",
      " [-1.0000393 ]], b = [ 29.97192138], loss = 0.0007741114403101067\n",
      "Step 6400: W = [[ 3.00023744]\n",
      " [-1.00002754]], b = [ 29.98032503], loss = 0.00038008432709902613\n",
      "Step 6500: W = [[ 3.00016325]\n",
      " [-1.00001893]], b = [ 29.98647261], loss = 0.0001796718249393602\n",
      "Step 6600: W = [[ 3.00011002]\n",
      " [-1.00001276]], b = [ 29.99088368], loss = 8.160007455597145e-05\n",
      "Step 6700: W = [[ 3.00007259]\n",
      " [-1.00000842]], b = [ 29.99398486], loss = 3.552579555733225e-05\n",
      "Step 6800: W = [[ 3.00004684]\n",
      " [-1.00000543]], b = [ 29.99611867], loss = 1.4791528945535082e-05\n",
      "Step 6900: W = [[ 3.00002952]\n",
      " [-1.00000342]], b = [ 29.99755388], loss = 5.875010027919988e-06\n",
      "Step 7000: W = [[ 3.00001815]\n",
      " [-1.0000021 ]], b = [ 29.9984963], loss = 2.2201029490380603e-06\n",
      "Step 7100: W = [[ 3.00001087]\n",
      " [-1.00000126]], b = [ 29.99909965], loss = 7.959331779338872e-07\n",
      "Step 7200: W = [[ 3.00000633]\n",
      " [-1.00000073]], b = [ 29.9994757], loss = 2.6990505538006566e-07\n",
      "Step 7300: W = [[ 3.00000358]\n",
      " [-1.00000041]], b = [ 29.99970354], loss = 8.629470303941071e-08\n",
      "Step 7400: W = [[ 3.00000196]\n",
      " [-1.00000023]], b = [ 29.99983751], loss = 2.5924656178322887e-08\n",
      "Step 7500: W = [[ 3.00000104]\n",
      " [-1.00000012]], b = [ 29.99991382], loss = 7.291495091231417e-09\n",
      "Step 7600: W = [[ 3.00000053]\n",
      " [-1.00000006]], b = [ 29.99995587], loss = 1.9125274533724553e-09\n",
      "Step 7700: W = [[ 3.00000026]\n",
      " [-1.00000003]], b = [ 29.99997822], loss = 4.658905268504023e-10\n",
      "Step 7800: W = [[ 3.00000012]\n",
      " [-1.00000001]], b = [ 29.99998966], loss = 1.0493431997456645e-10\n",
      "Step 7900: W = [[ 3.00000006]\n",
      " [-1.00000001]], b = [ 29.99999529], loss = 2.174926298223533e-11\n",
      "Step 8000: W = [[ 3.00000002]\n",
      " [-1.        ]], b = [ 29.99999795], loss = 4.127162003619358e-12\n",
      "Step 8100: W = [[ 3.00000001]\n",
      " [-1.        ]], b = [ 29.99999915], loss = 7.131183451984487e-13\n",
      "Step 8200: W = [[ 3.]\n",
      " [-1.]], b = [ 29.99999966], loss = 1.1153680383569131e-13\n",
      "Step 8300: W = [[ 3.]\n",
      " [-1.]], b = [ 29.99999987], loss = 1.5691562861835222e-14\n",
      "Step 8400: W = [[ 3.]\n",
      " [-1.]], b = [ 29.99999996], loss = 1.972108901165974e-15\n",
      "Step 8500: W = [[ 3.]\n",
      " [-1.]], b = [ 29.99999999], loss = 2.197825021698395e-16\n",
      "Step 8600: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 2.154574732614257e-17\n",
      "Step 8700: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 1.841763578800385e-18\n",
      "Step 8800: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 1.3596946074901695e-19\n",
      "Step 8900: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 8.579903379402663e-21\n",
      "Step 9000: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 4.577444597868918e-22\n",
      "Step 9100: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 2.0407845502019508e-23\n",
      "Step 9200: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 7.530377848818394e-25\n",
      "Step 9300: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 2.3780054215706356e-26\n",
      "Step 9400: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 7.3067452485191e-27\n",
      "Step 9500: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 8.222454987299651e-27\n",
      "Step 9600: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 7.185576213477152e-27\n",
      "Step 9700: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 8.111383371844532e-27\n",
      "Step 9800: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 7.266355570171785e-27\n",
      "Step 9900: W = [[ 3.]\n",
      " [-1.]], b = [ 30.], loss = 7.266355570171785e-27\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "#for i in range(100000):\n",
    "    sess.run(train, feed_dict={X:X_data, y:y_data})\n",
    "    if i % 1000 == 0:\n",
    "    #if i % 1000 == 0:    \n",
    "        print('Step {}: W = {}, b = {}, loss = {}'.format(i,\n",
    "                sess.run(W), sess.run(b), sess.run(loss, feed_dict={X:X_data, y:y_data})))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
